{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fathanzys/NLP-Fathan/blob/NLP_Code/tugas2_0102522024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9c8c3b3",
      "metadata": {
        "id": "a9c8c3b3"
      },
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "## Tugas 1: Regular Expressions & Model Bahasa N-gram\n",
        "\n",
        "### Mekanisme\n",
        "\n",
        "Anda hanya diwajibkan untuk mengumpulkan file ini saja ke uploader yang disediakan di https://elearning.uai.ac.id/. Ganti nama file ini saat pengumpulan menjadi **tugas1_NIM.ipynb**.\n",
        "\n",
        "**Keterlambatan**: Pengumpulan tugas yang melebihi tenggat yang telah ditentukan tidak akan diterima. Keterlambatan akan berakibat pada nilai nol untuk tugas ini.\n",
        "\n",
        "**Kolaborasi**: Anda diperbolehkan untuk berdiskusi dengan teman Anda, tetapi dilarang keras menyalin kode maupun tulisan dari teman Anda.\n",
        "\n",
        "### Petunjuk\n",
        "\n",
        "Pastikan jawaban Anda singkat, padat, dan jelas. Mayoritas pertanyaan yang diberikan dapat dijawab dalam 3-4 kalimat saja."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2bd648",
      "metadata": {
        "id": "fc2bd648"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9abe8d33",
      "metadata": {
        "id": "9abe8d33"
      },
      "source": [
        "## 1. Regular Expressions (5 poin)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08817304",
      "metadata": {
        "id": "08817304"
      },
      "source": [
        "### Soal 1.1 (2 poin)\n",
        "\n",
        "Cari pola regular expression yang dapat mencocokkan semua elemen di dalam `words_a`, tetapi tidak cocok dengan apa pun di dalam `words_b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6320c1af",
      "metadata": {
        "id": "6320c1af"
      },
      "outputs": [],
      "source": [
        "words_a = [\n",
        "    \"membacakan\",\n",
        "    \"menuliskan\",\n",
        "    \"melihatkan\",\n",
        "    \"mendengarkan\" ,\n",
        "    \"mengajarkan\",\n",
        "    \"menarikan\",\n",
        "    \"menyanyikan\" ,\n",
        "    \"memasakkan\",\n",
        "    \"mencucikan\",\n",
        "    \"membelikan\",\n",
        "    \"menjualkan\",\n",
        "    \"memberikan\" ,\n",
        "]\n",
        "\n",
        "words_b = [\n",
        "    \"rumah\",\n",
        "    \"meja\",\n",
        "    \"kursi\",\n",
        "    \"ikan\",\n",
        "    \"semen\",\n",
        "    \"ramen\" ,\n",
        "    \"akan\",\n",
        "    \"bukan\" ,\n",
        "    \"mental\",\n",
        "]\n",
        "pattern = r\"me[a-z]+kan$\" #<< jawabannya, karena\n",
        "#pada words_a, semua kata berawalan \"me\", diikuti oleh hruf kecil (a-z) 1 atau lebih, dan diakhiri \"kan\", jadi cocok dengan regex.\n",
        "#pada words_b, tidak ada pola seperti itu (tidak di mulai \"me\" lalu banyak huruf lalu \"kan\" di akhir), jadi tidak cocok dengan regex.\n",
        "\n",
        "assert pd.Series(words_a).str.contains(pattern).all()\n",
        "assert not pd.Series(words_b).str.match(pattern).any()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "945567fa",
      "metadata": {
        "id": "945567fa"
      },
      "source": [
        "### Soal 1.2 (3 poin)\n",
        "\n",
        "Cari pola regular expression yang dapat mencocokkan semua elemen di dalam `buah_a`, tetapi tidak cocok dengan apa pun di dalam `buah_b`. Anda hanya boleh menggunakan maksimal 6 karakter untuk pola yang dihasilkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d3f707",
      "metadata": {
        "id": "85d3f707",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "buah_a = [\n",
        "    \"pisang\",\n",
        "    \"mangga\",\n",
        "    \"rambutan\",\n",
        "    \"durian\",\n",
        "    \"salak\",\n",
        "    \"duku\",\n",
        "    \"kelapa\",\n",
        "    \"sirsak\",\n",
        "    \"belimbing\",\n",
        "    \"manggis\",\n",
        "]\n",
        "\n",
        "buah_b = [\n",
        "    \"pir\",\n",
        "    \"stroberi\",\n",
        "    \"ceri\",\n",
        "    \"kiwi\",\n",
        "    \"leci\",\n",
        "    \"persik\",\n",
        "]\n",
        "\n",
        "pattern = r\"[aum]\" #<< jawabannya, karena\n",
        "#pada buah_a, karena ada huruf a/u/m dan cocok regex nya\n",
        "#pada buah_b,  tidak cocok regex nya karena ngga ada huruf a/u/m\n",
        "\n",
        "assert len(pattern) <= 6\n",
        "assert pd.Series(buah_a).str.contains(pattern).all()\n",
        "assert not pd.Series(buah_b).str.contains(pattern).any()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2482f3",
      "metadata": {
        "id": "dc2482f3"
      },
      "source": [
        "## 2. Model Bahasa N-gram (15 poin)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01172ef2",
      "metadata": {
        "id": "01172ef2"
      },
      "source": [
        "### Deskripsi Dataset\n",
        "\n",
        "Dataset yang Anda akan gunakan dalam tugas ini adalah [Indonesian News Corpora 300K](https://wortschatz.uni-leipzig.de/en/download/Indonesian#ind_news_2024) tahun 2024 dari Leipzig Corpora Collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f1d1459",
      "metadata": {
        "id": "0f1d1459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77e7ab7-1b3e-4df9-93ce-18fce2be495e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-a2a6c86ed52e>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  sentences = pd.read_csv(\n"
          ]
        }
      ],
      "source": [
        "sentences = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/aliakbars/uai-nlp/refs/heads/main/datasets/ind_news_2024_300K-sentences.txt\",\n",
        "    sep=\"\\\\t\",\n",
        "    names=[\"index\", \"text\"],\n",
        ")\n",
        "del sentences[\"index\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479e18a4",
      "metadata": {
        "id": "479e18a4"
      },
      "source": [
        "### Soal 2.1 (2 poin)\n",
        "\n",
        "Bagilah dataset menjadi data latih dan data uji dengan rasio 80:20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e423be",
      "metadata": {
        "id": "e3e423be"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(sentences, test_size=0.2, random_state=42)\n",
        "#melatih dan meng tes data\n",
        "assert len(train) == 240000\n",
        "assert len(test) == 60000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4LsRGAR1N0Ff"
      },
      "id": "4LsRGAR1N0Ff"
    },
    {
      "cell_type": "markdown",
      "id": "13e3f971",
      "metadata": {
        "id": "13e3f971"
      },
      "source": [
        "### Soal 2.2 (2 poin)\n",
        "\n",
        "Buatlah tabel `unigram_df` yang menghasilkan **unigram** dari data latih yang telah dihasilkan di atas. Gunakan [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) untuk proses tokenisasi dan menghasilkan unigramnya, serta pola token default `'(?u)\\\\b\\\\w\\\\w+\\\\b'`.\n",
        "\n",
        "Contoh hasil tabel:\n",
        "| word      |   freq |\n",
        "|:----------|-------:|\n",
        "| diketahui |   2654 |\n",
        "| layanan   |   2015 |\n",
        "| maju      |   1386 |\n",
        "| aksi      |   1707 |\n",
        "| januari   |   1316 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e38d629c",
      "metadata": {
        "id": "e38d629c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f51b06-9c79-4543-d9da-47fde3904477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    word   freq\n",
            "0   yang  93794\n",
            "1    dan  82683\n",
            "2     di  80752\n",
            "3    ini  42942\n",
            "4  untuk  40433\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b\")\n",
        "\n",
        "#memlakukan transformasi pada data latih untuk menghasilkan representasi unigram\n",
        "X_train = vectorizer.fit_transform(train['text'])\n",
        "\n",
        "#menghitung jumlah kemunculan setiap kata (unigram)\n",
        "word_counts = X_train.sum(axis=0)\n",
        "words = vectorizer.get_feature_names_out()\n",
        "freq = np.asarray(word_counts).flatten()\n",
        "\n",
        "#membuat dataframe untuk menyimpan kata-kata dan frekuensinya\n",
        "unigram_df = pd.DataFrame({\"word\": words, \"freq\": freq})\n",
        "unigram_df = unigram_df.sort_values(by=\"freq\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "#memastikan bahwa dataframe memiliki kolom, 'word' dan 'freq'\n",
        "assert [\"word\", \"freq\"] == unigram_df.columns.to_list()\n",
        "\n",
        "#menampilkan 5 baris pertama dari unigram_df\n",
        "print(unigram_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "961fdae1",
      "metadata": {
        "id": "961fdae1"
      },
      "source": [
        "### Soal 2.3 (3 poin)\n",
        "\n",
        "Buatlah tabel `bigram_df` yang menghasilkan **bigram** dari data latih yang telah dihasilkan di atas. Gunakan [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) untuk proses tokenisasi dan menghasilkan bigram, serta pola token default `'(?u)\\\\b\\\\w\\\\w+\\\\b'`. Tambahkan `ooo` sebagai _start token_ dan `zzz` sebagai _end token_.\n",
        "\n",
        "Contoh hasil tabel:\n",
        "| word          | next_word   |   freq |\n",
        "|:--------------|:------------|-------:|\n",
        "| akan          | ada         |    461 |\n",
        "| sebagai       | bentuk      |    365 |\n",
        "| dua           | orang       |    363 |\n",
        "| internasional | zzz         |    385 |\n",
        "| kasus         | ini         |    535 |\n",
        "| kami          | berharap    |    379 |\n",
        "| informasi     | yang        |    398 |\n",
        "| yang          | kita        |    465 |\n",
        "| pada          | musim       |    325 |\n",
        "| tahun         | zzz         |   1060 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c74d523",
      "metadata": {
        "id": "4c74d523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6c856c-3fa6-4119-c09b-f0188372d073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       word next_word   freq\n",
            "0      2024       zzz  11777\n",
            "1       ooo     namun   4605\n",
            "2       ini       zzz   4525\n",
            "3      saat       ini   4259\n",
            "4  tersebut       zzz   4076\n"
          ]
        }
      ],
      "source": [
        "def add_start_end_tokens(text):\n",
        "    return \"ooo \" + text + \" zzz\"\n",
        "\n",
        "train['text_with_tokens'] = train['text'].apply(add_start_end_tokens)\n",
        "\n",
        "#menggunakan countvectorizer untuk ekstraksi bigram dari teks\n",
        "vectorizer = CountVectorizer(\n",
        "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",  #pola regex\n",
        "    ngram_range=(2, 2),\n",
        "    max_features=10000,\n",
        "    min_df=5\n",
        ")\n",
        "\n",
        "#transformasi pada datatrain untuk menghasilkan representasi bigram\n",
        "X_train = vectorizer.fit_transform(train['text_with_tokens'])\n",
        "\n",
        "#membuat dataframe yg menyimpang variabel biagram\n",
        "bigram_df = pd.DataFrame(\n",
        "    {\n",
        "        'bigram': vectorizer.get_feature_names_out(),\n",
        "        'freq': X_train.sum(axis=0).A1\n",
        "    }\n",
        ").sort_values(by=\"freq\", ascending=False).reset_index(drop=True)  #mengurutkan berdasarkan freq (frekuensi)\n",
        "\n",
        "#mempisahkan bigram menjadi dua kolom 'word' dan 'next_word'\n",
        "bigram_df[['word', 'next_word']] = bigram_df['bigram'].str.split(expand=True)\n",
        "bigram_df = bigram_df[['word', 'next_word', 'freq']]\n",
        "bigram_df = bigram_df.dropna()\n",
        "\n",
        "#memastikan bahwa kolom yang diinginkan ada dan sesuai\n",
        "assert [\"word\", \"next_word\", \"freq\"] == bigram_df.columns.to_list()\n",
        "assert \"ooo\" in bigram_df[\"word\"].to_list()\n",
        "assert \"zzz\" in bigram_df[\"next_word\"].to_list()\n",
        "\n",
        "#menampilkan 5 baris pertama dari bigram_df\n",
        "print(bigram_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e915dc",
      "metadata": {
        "id": "46e915dc"
      },
      "source": [
        "### Soal 2.4 (5 poin)\n",
        "\n",
        "Implementasikan kode yang menghasilkan array berisi skor (*log probability*) jika diberikan sebuah kalimat. Petunjuk implementasi:\n",
        "1. Gunakan tabel unigram dan bigram yang telah dihasilkan di soal sebelumnya.\n",
        "1. Gunakan metode Stupid backoff yang menggunakan parameter `alpha` untuk mengatasi kasus bigram yang tidak ditemukan.\n",
        "1. Gunakan metode Laplace smoothing untuk menangani kasus unigram yang tidak ditemukan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5fa917",
      "metadata": {
        "id": "5a5fa917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22378c23-cb1d-4fa4-ea7d-e08abb123d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-15.200211900904204\n",
            "-16.11650263277836\n"
          ]
        }
      ],
      "source": [
        "class BigramModel:\n",
        "    def __init__(self, unigram_df: pd.DataFrame, bigram_df: pd.DataFrame, alpha: float = 0.4):\n",
        "        #menginisialisasi model dengan data unigram dan bigram serta alpha untuk backoff\n",
        "        self.unigram_df = unigram_df\n",
        "        self.bigram_df = bigram_df\n",
        "        self.alpha = alpha\n",
        "        self.N = self.unigram_df.freq.sum()  #total dari frekuensi kata\n",
        "        self.V = len(self.unigram_df)  #jumlah kata unik\n",
        "\n",
        "    def score_unigram(self, word: str) -> float:\n",
        "        #menghitung skor unigram menggunakan teknik laplace smoothing\n",
        "        count = self.unigram_df.loc[self.unigram_df['word'] == word, 'freq'].sum()\n",
        "        prob = (count + 1) / (self.N + self.V)\n",
        "        return np.log(prob)\n",
        "\n",
        "    def score(self, word: str, prev_word: str) -> float:\n",
        "        #menghitung skor bigram atau menggunakan teknik backoff\n",
        "        bigram_count = self.bigram_df[\n",
        "            (self.bigram_df['word'] == prev_word) &\n",
        "            (self.bigram_df['next_word'] == word)\n",
        "        ]['freq'].sum()\n",
        "\n",
        "        prev_count = self.unigram_df.loc[self.unigram_df['word'] == prev_word, 'freq'].sum()\n",
        "\n",
        "        if bigram_count > 0 and prev_count > 0:\n",
        "            prob = bigram_count / prev_count\n",
        "            return np.log(prob)\n",
        "        else:\n",
        "            #teknik backoff menggunakan unigram dengan smoothing\n",
        "            backoff_prob = self.alpha * ((self.unigram_df.loc[\n",
        "                self.unigram_df['word'] == word, 'freq'\n",
        "            ].sum() + 1) / (self.N + self.V))\n",
        "            return np.log(backoff_prob)\n",
        "\n",
        "    def sentence_score(self, sentence: str, n: int = 2) -> np.ndarray:\n",
        "        #menghitung skor untuk seluruh kalimat berdasarkan bigram atau unigram\n",
        "        words = sentence.strip().split()\n",
        "        if n == 2:\n",
        "            return np.array([self.score(words[1], words[i-1]) for i in range(1, len(words))])\n",
        "        elif n == 1:\n",
        "            return np.array([self.score_unigram(word) for word in words])\n",
        "        else:\n",
        "            raise NotImplemented(\"Saat ini hanya bisa untuk n=1 atau n=2\")\n",
        "\n",
        "\n",
        "\n",
        "bm = BigramModel(unigram_df, bigram_df, alpha=0.4)\n",
        "assert bm.score_unigram(\"qqq\") > bm.score(\"qqq\", \"xxx\")\n",
        "assert bm.score(\"qqq\", \"xxx\") == np.log(\n",
        "    0.4 * 1 / (unigram_df.freq.sum() + len(unigram_df))\n",
        ")\n",
        "assert bm.score(\"mana\", \"di\") <= 0\n",
        "assert bm.score(\"mungkin\", \"tidak\") > bm.score(\"qqq\", \"xxx\")\n",
        "assert bm.score(\"satu\", \"salah\") > bm.score(\"tangkap\", \"salah\")\n",
        "assert (bm.sentence_score(\"salah satu\") <= 0).all()\n",
        "\n",
        "print(bm.score_unigram(\"qqq\"))\n",
        "print(bm.score(\"qqq\", \"xxx\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f2b476",
      "metadata": {
        "id": "a9f2b476"
      },
      "source": [
        "### Soal 2.5.a (2 poin)\n",
        "\n",
        "Implementasikan fungsi untuk menghitung perplexity dalam logaritma. Fungsi ini hanya menerima masukan berupa array berisi $\\log P(w_i)$.\n",
        "\n",
        "$$\n",
        "PP(W) = \\sqrt[N]{\\frac{1}{\\prod_{i=1}^N P(w_i)}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2499946e",
      "metadata": {
        "id": "2499946e"
      },
      "outputs": [],
      "source": [
        "def perplexity(log_probs: np.ndarray):\n",
        "    N = len(log_probs)  # menghitung jumlah elemen dalam log probabilitis\n",
        "    log_sum = np.sum(log_probs)  # menjumlahkan semua nilai log probabilities\n",
        "    return np.exp(-log_sum / N)  # menghiitung dan kembalikan perplexity dengan rumus yang sesuai\n",
        "\n",
        "# memverifikasi dengan log probabilities yang semuanya 0, seharusnya hasilnya 1\n",
        "assert perplexity(np.array([0., 0., 0.])) == 1\n",
        "# memverifikasi dengan log probabilities -10 dan -20, seharusnya hasilnya exp(15)\n",
        "assert perplexity(np.array([-10., -20.])) == np.exp(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6a33d9",
      "metadata": {
        "id": "ba6a33d9"
      },
      "source": [
        "### Soal 2.5.b (1 poin)\n",
        "\n",
        "Berdasarkan kalimat contoh yang diberikan, periksa dan pastikan bahwa perplexity dari `BigramModel` lebih kecil daripada model unigram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f081b329",
      "metadata": {
        "id": "f081b329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc24024d-3a36-4060-cfd7-63974d7bfdd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Unigram: 1642.5858621370896\n",
            "Perplexity Bigram: 579.6947395924054\n"
          ]
        }
      ],
      "source": [
        "example = \"pengakuan tersebut diungkapkan dalam wawancara dengan media\"\n",
        "\n",
        "#score kalimat menggunakan Unigram\n",
        "unigram_log_prob = []\n",
        "for word in example.split():\n",
        "    unigram_log_prob.append(bm.score_unigram(word))\n",
        "unigram_log_prob = np.array(unigram_log_prob)\n",
        "\n",
        "#score kalimat menggunakan bigram\n",
        "bigram_log_prob = bm.sentence_score(example)\n",
        "\n",
        "#menghitung perplexity\n",
        "unigram_perplexity = perplexity(unigram_log_prob)\n",
        "bigram_perplexity = perplexity(bigram_log_prob)\n",
        "\n",
        "print(\"Perplexity Unigram:\", unigram_perplexity)\n",
        "print(\"Perplexity Bigram:\", bigram_perplexity)\n",
        "\n",
        "assert bigram_perplexity < unigram_perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f122c9",
      "metadata": {
        "id": "86f122c9"
      },
      "source": [
        "### Soal 2.6 (3 poin)\n",
        "\n",
        "Ambil 30 sampel dari data uji. Hitunglah nilai rata-rata berbobot (_weighted average_) perplexity per kalimat pada data uji dengan menggunakan jumlah kata per kalimat sebagai bobotnya.\n",
        "\n",
        "Pastikan bahwa:\n",
        "1. Metode tokenisasi dan preprocessing yang dilakukan sama dengan soal 2.2 dan 2.3.\n",
        "1. Nilai perplexity dihitung untuk model unigram dan bigram dengan backoff.\n",
        "\n",
        "_Petunjuk: Gunakan metode `.findall()`_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e803681",
      "metadata": {
        "id": "8e803681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3ddb26-23c3-441f-9ac8-8d0e93859d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rata-rata berat perplexity unigram : 211752.0274204288\n",
            "rata-rata berat perplexity bigram : 4688909.321733292\n"
          ]
        }
      ],
      "source": [
        "def compute_perplexity(log_probs: np.ndarray, n_tokens: int) -> float:\n",
        "    return np.exp(-log_probs.sum() / n_tokens)\n",
        "\n",
        "# mengambil data dari sentences uji\n",
        "sample_sentences = np.array(test).flatten()\n",
        "\n",
        "# memiilih 30 kalimat acak dari data uji\n",
        "np.random.seed(42)\n",
        "selected_sentences = np.random.choice(sample_sentences, size=30, replace=False)\n",
        "\n",
        "# variabel untuk menyimpan perplexity dan jumlah kata per kalimat\n",
        "unigram_perplexities = []\n",
        "bigram_perplexities = []\n",
        "word_counts = []\n",
        "\n",
        "# polaa regex untuk tokenisasi (ambil kata yang panjangnya >= 2 huruf)\n",
        "token_pattern = r'\\b\\w\\w+\\b'\n",
        "\n",
        "# memproses setiap kalimat\n",
        "for sentence in selected_sentences:\n",
        "    tokens = re.findall(token_pattern, sentence.lower())  # Tokenisasi kalimat\n",
        "    if not tokens:\n",
        "        continue\n",
        "\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # menghiitung log-probabilitas untuk unigram dan bigram\n",
        "    unigram_log_probs = bm.sentence_score(sentence, n=1)\n",
        "    bigram_log_probs = bm.sentence_score(sentence, n=2)\n",
        "\n",
        "    # menghiititung perplexity untuk unigram dan bigram\n",
        "    unigram_perplexity = compute_perplexity(unigram_log_probs, num_tokens)\n",
        "    bigram_perplexity = compute_perplexity(bigram_log_probs, num_tokens)\n",
        "\n",
        "    # menyimpan hasil perplexity dan jumlah kata\n",
        "    unigram_perplexities.append(unigram_perplexity)\n",
        "    bigram_perplexities.append(bigram_perplexity)\n",
        "    word_counts.append(num_tokens)\n",
        "\n",
        "# menghiitung rata-rata berbobot perplexity\n",
        "total_words = np.sum(word_counts)\n",
        "weighted_unigram_avg = np.sum(np.array(unigram_perplexities) * np.array(word_counts)) / total_words\n",
        "weighted_bigram_avg = np.sum(np.array(bigram_perplexities) * np.array(word_counts)) / total_words\n",
        "\n",
        "# menampilkan hasil rata-rata perplexity\n",
        "print(\"rata-rata berat perplexity unigram :\", weighted_unigram_avg)\n",
        "print(\"rata-rata berat perplexity bigram :\", weighted_bigram_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddaa046e",
      "metadata": {
        "id": "ddaa046e"
      },
      "source": [
        "### Soal 2.7 (2 poin)\n",
        "\n",
        "Berikan kesimpulan dari analisis yang sudah dilakukan pada bagian kedua dari tugas ini."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5576ff95",
      "metadata": {
        "id": "5576ff95"
      },
      "source": [
        "Saya mempelajari dan mendapatkan insight dari tugas ini dimulai dengan mencari regular expression (regex) dan menemukan pola dari data yang sudah diberikan, seperti pada soal 1.1 dengan mencari pola yang cocok untuk words_a tetapi tidak cocok dengan words_b, dan pada soal 1.2 dengan mencari pola yang cocok untuk buah_a tetapi tidak cocok dengan buah_b, dengan batasan 6 karakter (<=). Pola regex yang ditemukan adalah r\"[aum]\", yang mencocokkan kata yang mengandung huruf 'a', 'u', atau 'm'.\n",
        "\n",
        "Selanjutnya, pada soal 2 yang membahas tentang model N-gram, saya memulai dengan membagi dataset menjadi data latih (240.000 baris) dan data uji (60.000 baris) pada soal 2.1. Pada soal 2.2, saya menghitung frekuensi kata yang muncul pada teks menggunakan CountVectorizer, yang mengubah teks menjadi angka untuk menunjukkan seberapa sering kata-kata muncul dalam dataset. Pada soal 2.3, saya menambahkan token 'ooo' dan 'zzz' sebagai penanda awal dan akhir kalimat, kemudian membuat kolom 'word', 'next_word', dan 'freq' untuk mencatat frekuensi kemunculan kata-kata dan pasangan kata.\n",
        "\n",
        "Pada soal 2.4, saya mempelajari implementasi model bigram dengan menggunakan teknik Laplace Smoothing dan Stupid Backoff untuk menghitung skor probabilitas unigram dan bigram. Hasil skor yang diperoleh (-15.200211900904204 dan -16.11650263277836) menunjukkan nilai negatif, yang mengindikasikan bahwa probabilitas urutan kata yang dihitung oleh model relatif rendah. Di soal 2.5a, saya mempelajari fungsi perplexity untuk menghitung tingkat kompleksitas model berdasarkan log probabilitas. Perplexity dihitung dengan dua contoh: pertama, dengan log probabilitas 0 (hasilnya 1 karena log(1) = 0), dan kedua, dengan log probabilitas -10 dan -20 (hasilnya exp(15)). Nilai perplexity yang lebih rendah menunjukkan model yang lebih baik dalam memprediksi urutan kata, sementara nilai yang lebih tinggi menunjukkan model yang kurang efektif.\n",
        "\n",
        "Pada soal 2.5b, saya menghitung perplexity untuk model unigram dan bigram. Proses ini melibatkan perhitungan probabilitas unigram dan bigram pada setiap kata dalam kalimat, kemudian menghitung log probabilitas dan perplexity untuk masing-masing model. Pada soal 2.6, saya menghitung rata-rata perplexity untuk model unigram dan bigram dengan menggunakan 30 kalimat acak dari data uji. Kalimat-kalimat ini diproses melalui tokenisasi dengan regex untuk kata yang memiliki panjang minimal 2 huruf, dan log-probabilitas dihitung untuk masing-masing model. Hasil rata-rata perplexity yang diperoleh adalah: untuk unigram 211752.0274204288 dan untuk bigram 4688909.321733292."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}